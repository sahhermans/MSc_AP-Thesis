{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyPfDoXB0GmT"
      },
      "outputs": [],
      "source": [
        "## Setup\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from datetime import datetime\n",
        "import p3DNets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A4u_TGBL-vZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#import torch.nn.modules.conv as conv\n",
        "#import CoordConv\n",
        "#from tensorflow.python.keras.layers import Layer, InputSpec\n",
        "#from tensorflow.keras import backend as K\n",
        "#from tensorflow.keras.utils import get_custom_objects\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aphZRzMRmrxE",
        "outputId": "ffc9d22a-680d-42e6-8e7f-e24573845a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#import torch.nn.modules.conv as conv\\n#import CoordConv\\n#from tensorflow.python.keras.layers import Layer, InputSpec\\n#from tensorflow.keras import backend as K\\n#from tensorflow.keras.utils import get_custom_objects\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1VyfwNk0Ky6"
      },
      "outputs": [],
      "source": [
        "def try_gpu():\n",
        "    \"\"\"\n",
        "    If GPU is available, return torch.device as cuda:0; else return torch.device\n",
        "    as cpu.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "# Try using gpu instead of cpu\n",
        "device = try_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq5RvviJ0Uav"
      },
      "outputs": [],
      "source": [
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "      if hasattr(layer, 'reset_parameters'):\n",
        "          print(f'Reset trainable parameters of layer = {layer}')\n",
        "          layer.reset_parameters()\n",
        "    \n",
        "def custom_loss(y_pred, y_batch):\n",
        "    \n",
        "    loss = torch.mean(torch.abs(y_batch - y_pred))*128\n",
        "    \n",
        "    constraint = torch.sum(torch.abs(-4 - torch.sum(y_pred, axis = 1)))/(y_batch.shape[0])\n",
        "    \n",
        "    return (loss + constraint)\n",
        "\n",
        "def custom_loss_orig(y_pred, y_batch):\n",
        "    \n",
        "    loss = torch.mean(torch.abs(y_batch - y_pred))\n",
        "    \n",
        "    constraint = torch.sum(torch.abs(-4 - torch.sum(y_pred, axis = 1)))/(128*(y_batch.shape[0]))\n",
        "    \n",
        "    return (loss + constraint)\n",
        "\n",
        "def evaluate_accuracy(data_loader, net, device):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    net.eval()  #make sure network is in evaluation mode\n",
        "\n",
        "    #init\n",
        "    loss_sum = torch.tensor([0], dtype=torch.float32, device=device)\n",
        "    con_sum = torch.tensor([0], dtype=torch.float32, device=device)\n",
        "    n = 0\n",
        "\n",
        "    for X, y in data_loader:\n",
        "        # Copy the data to device.\n",
        "        X, y = X.to(device).to_dense(), y.to(device)\n",
        "        with torch.no_grad():\n",
        "         \n",
        "            loss_sum += torch.sum(torch.abs(net(X) - y))/128\n",
        "            con_sum += torch.sum(torch.abs(torch.sum(net(X), axis = 1) - torch.sum(y,axis = 1)))/128\n",
        "            \n",
        "            n += y.shape[0] #increases with the number of samples in the batch\n",
        "    return loss_sum.item()/n, con_sum.item()/n\n",
        "\n",
        "\n",
        "def train_test(epochs, net, device, train_loader, test_loader, optimizer, criterion):\n",
        "    \"\"\"Training and testing function of FCN\"\"\"\n",
        "    \n",
        "    startTime = datetime.now()\n",
        "    \n",
        "    # Define list to store losses and performances of each iteration\n",
        "    train_losses = []\n",
        "    train_losss = []\n",
        "    test_losss = []\n",
        "    train_cons = []\n",
        "    test_cons = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Network in training mode and to device\n",
        "        net.train()\n",
        "        net.to(device)\n",
        "        \n",
        "        #for name, module in net.named_modules():\n",
        "        #    if isinstance(module, torch.nn.Conv2d):\n",
        "        #        module.weight = torch.nn.Parameter(module.weight.data.to_sparse())\n",
        "        #        module.bias = torch.nn.Parameter(module.bias.data.to_sparse())\n",
        "\n",
        "        # Training loop\n",
        "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "\n",
        "            # Set to same device\n",
        "            \n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            x_batch = x_batch.to_dense()\n",
        "            \n",
        "            # Set the gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform forward pass\n",
        "            y_pred = net(x_batch)\n",
        "\n",
        "            # Compute the loss\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            train_losses.append(loss.detach().cpu().numpy())\n",
        "            \n",
        "            # Backward computation and update\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\n",
        "           \n",
        "        print(datetime.now() - startTime)\n",
        "        \n",
        "        elif epoch == 25: \n",
        "            learning_rate = 0.0001\n",
        "            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.5)\n",
        "        elif epoch == 50:\n",
        "            learning_rate = 0.00001\n",
        "            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.5)\n",
        "        elif epoch == 75:\n",
        "            learning_rate = 0.000001\n",
        "            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.5) \n",
        "                    \n",
        "        if  epoch == 0 or epoch%5 == 0:\n",
        "            # Compute train and test error\n",
        "            train_loss, train_con = evaluate_accuracy(train_loader, net.to(device), device)\n",
        "            test_loss, test_con = evaluate_accuracy(test_loader, net.to(device), device)\n",
        "            \n",
        "            # Development of performance\n",
        "            train_losss.append(train_loss)\n",
        "            test_losss.append(test_loss)\n",
        "            \n",
        "            train_cons.append(train_con)\n",
        "            test_cons.append(test_con)\n",
        "    \n",
        "            # Print performance\n",
        "            print('Epoch: {:.0f}'.format(epoch+1))\n",
        "            print('Loss on train set: {:.7f}'.format(train_loss))\n",
        "            print('Loss on test set: {:.7f}'.format(test_loss))\n",
        "            print('Con on train set: {:.7f}'.format(train_con))\n",
        "            print('Con on test set: {:.7f}'.format(test_con))\n",
        "            print('')\n",
        "\n",
        "    print(datetime.now() - startTime)\n",
        "    \n",
        "    return net, train_losses, train_losss, test_losss, train_cons, test_cons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWABQmmt0XrZ"
      },
      "outputs": [],
      "source": [
        "in_channels = 1\n",
        "hidden_channels = [4,8,16,32,64,128,256]\n",
        "out_features = 128\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 101\n",
        "criterion = custom_loss\n",
        "criterion_orig = custom_loss_orig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-GctT9m0W8F"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.load('test_loader_d_3D')\n",
        "train_loader = torch.load('train_loader_d_3D_8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cV7Jr-ysJ2dM",
        "outputId": "283c0a17-fd00-4100-b506-13ec0d9ed825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reset trainable parameters of layer = Conv3d(1, 16, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=128, bias=True)\n",
            "0:04:52.784312\n",
            "Epoch: 1\n",
            "Loss on train set: 0.0369821\n",
            "Loss on test set: 0.0398789\n",
            "Con on train set: 0.0007475\n",
            "Con on test set: 0.0014822\n",
            "\n",
            "0:12:18.315552\n",
            "0:17:02.715907\n",
            "0:21:47.191280\n",
            "0:26:31.655546\n",
            "0:31:16.186788\n",
            "Epoch: 6\n",
            "Loss on train set: 0.0312387\n",
            "Loss on test set: 0.0349322\n",
            "Con on train set: 0.0014493\n",
            "Con on test set: 0.0009035\n",
            "\n",
            "0:38:42.131288\n",
            "0:43:26.833737\n",
            "0:48:11.539144\n",
            "0:52:56.053750\n",
            "0:57:40.611569\n",
            "Epoch: 11\n",
            "Loss on train set: 0.0310088\n",
            "Loss on test set: 0.0367767\n",
            "Con on train set: 0.0004512\n",
            "Con on test set: 0.0001891\n",
            "\n",
            "1:05:05.581271\n",
            "1:09:49.944096\n",
            "1:14:34.343195\n",
            "1:19:18.739377\n",
            "1:24:03.103323\n",
            "Epoch: 16\n",
            "Loss on train set: 0.0306208\n",
            "Loss on test set: 0.0348613\n",
            "Con on train set: 0.0001693\n",
            "Con on test set: 0.0003107\n",
            "\n",
            "1:31:27.025296\n",
            "1:36:11.523522\n",
            "1:40:55.960214\n",
            "1:45:40.364643\n",
            "1:50:24.739694\n",
            "Epoch: 21\n",
            "Loss on train set: 0.0314102\n",
            "Loss on test set: 0.0367023\n",
            "Con on train set: 0.0003455\n",
            "Con on test set: 0.0003233\n",
            "\n",
            "1:57:47.969109\n",
            "2:02:32.407225\n",
            "2:07:16.821253\n",
            "2:12:01.242601\n",
            "2:16:45.656380\n",
            "Epoch: 26\n",
            "Loss on train set: 0.0303978\n",
            "Loss on test set: 0.0352723\n",
            "Con on train set: 0.0001085\n",
            "Con on test set: 0.0002893\n",
            "\n",
            "2:24:08.884041\n",
            "2:28:52.892399\n",
            "2:33:36.890073\n",
            "2:38:20.854220\n",
            "2:43:04.794438\n",
            "Epoch: 31\n",
            "Loss on train set: 0.0309334\n",
            "Loss on test set: 0.0361909\n",
            "Con on train set: 0.0001207\n",
            "Con on test set: 0.0001277\n",
            "\n",
            "2:50:27.687503\n",
            "2:55:11.688522\n",
            "2:59:55.636363\n",
            "3:04:39.583820\n",
            "3:09:23.516600\n",
            "Epoch: 36\n",
            "Loss on train set: 0.0305273\n",
            "Loss on test set: 0.0355688\n",
            "Con on train set: 0.0001037\n",
            "Con on test set: 0.0001035\n",
            "\n",
            "3:16:46.164922\n",
            "3:21:30.131476\n",
            "3:26:14.039747\n",
            "3:30:57.968613\n",
            "3:35:41.877836\n",
            "Epoch: 41\n",
            "Loss on train set: 0.0302747\n",
            "Loss on test set: 0.0352662\n",
            "Con on train set: 0.0001582\n",
            "Con on test set: 0.0003641\n",
            "\n",
            "3:43:04.747050\n",
            "3:47:48.690242\n",
            "3:52:32.591475\n",
            "3:57:16.655668\n",
            "4:02:00.569586\n",
            "Epoch: 46\n",
            "Loss on train set: 0.0300250\n",
            "Loss on test set: 0.0345638\n",
            "Con on train set: 0.0000885\n",
            "Con on test set: 0.0000768\n",
            "\n",
            "4:09:23.651512\n",
            "4:14:07.601320\n",
            "4:18:51.588909\n",
            "4:23:35.545248\n",
            "4:28:19.402063\n",
            "Epoch: 51\n",
            "Loss on train set: 0.0306692\n",
            "Loss on test set: 0.0346213\n",
            "Con on train set: 0.0001229\n",
            "Con on test set: 0.0001697\n",
            "\n",
            "4:35:40.852357\n",
            "4:40:24.682235\n",
            "4:45:08.500861\n",
            "4:49:52.344633\n",
            "4:54:36.183963\n",
            "Epoch: 56\n",
            "Loss on train set: 0.0280676\n",
            "Loss on test set: 0.0332469\n",
            "Con on train set: 0.0000925\n",
            "Con on test set: 0.0001157\n",
            "\n",
            "5:01:58.273666\n",
            "5:06:42.093159\n",
            "5:11:25.957120\n",
            "5:16:09.813252\n",
            "5:20:53.657557\n",
            "Epoch: 61\n",
            "Loss on train set: 0.0279775\n",
            "Loss on test set: 0.0329439\n",
            "Con on train set: 0.0000476\n",
            "Con on test set: 0.0000778\n",
            "\n",
            "5:28:15.374927\n",
            "5:32:59.205104\n",
            "5:37:43.055630\n",
            "5:42:26.917898\n",
            "5:47:10.806956\n",
            "Epoch: 66\n",
            "Loss on train set: 0.0279623\n",
            "Loss on test set: 0.0328849\n",
            "Con on train set: 0.0000591\n",
            "Con on test set: 0.0000989\n",
            "\n",
            "5:54:32.817197\n",
            "5:59:16.690903\n",
            "6:04:00.503363\n",
            "6:08:44.404968\n",
            "6:13:28.399801\n",
            "Epoch: 71\n",
            "Loss on train set: 0.0278484\n",
            "Loss on test set: 0.0327526\n",
            "Con on train set: 0.0000450\n",
            "Con on test set: 0.0000505\n",
            "\n",
            "6:20:50.390903\n",
            "6:25:34.256443\n",
            "6:30:18.106134\n",
            "6:35:01.993740\n",
            "6:39:45.841798\n",
            "Epoch: 76\n",
            "Loss on train set: 0.0278958\n",
            "Loss on test set: 0.0328847\n",
            "Con on train set: 0.0000439\n",
            "Con on test set: 0.0000804\n",
            "\n",
            "6:47:07.755338\n",
            "6:51:51.603149\n",
            "6:56:34.430581\n",
            "7:01:17.212251\n",
            "7:06:00.019197\n",
            "Epoch: 81\n",
            "Loss on train set: 0.0275785\n",
            "Loss on test set: 0.0326009\n",
            "Con on train set: 0.0000504\n",
            "Con on test set: 0.0000578\n",
            "\n",
            "7:13:13.928946\n",
            "7:17:56.879675\n",
            "7:22:40.013596\n",
            "7:27:22.967841\n",
            "7:32:05.891610\n",
            "Epoch: 86\n",
            "Loss on train set: 0.0275084\n",
            "Loss on test set: 0.0325522\n",
            "Con on train set: 0.0000498\n",
            "Con on test set: 0.0000835\n",
            "\n",
            "7:39:18.096496\n",
            "7:44:00.899167\n",
            "7:48:43.698802\n",
            "7:53:26.853232\n",
            "7:58:10.070759\n",
            "Epoch: 91\n",
            "Loss on train set: 0.0275265\n",
            "Loss on test set: 0.0325024\n",
            "Con on train set: 0.0000443\n",
            "Con on test set: 0.0000914\n",
            "\n",
            "8:05:24.107006\n",
            "8:10:07.290041\n",
            "8:14:50.447723\n",
            "8:19:33.642749\n",
            "8:24:16.928994\n",
            "Epoch: 96\n",
            "Loss on train set: 0.0275048\n",
            "Loss on test set: 0.0326356\n",
            "Con on train set: 0.0000548\n",
            "Con on test set: 0.0000864\n",
            "\n",
            "8:31:31.783802\n",
            "8:36:15.154182\n",
            "8:40:58.393191\n",
            "8:45:41.839497\n",
            "8:50:25.118678\n",
            "Epoch: 101\n",
            "Loss on train set: 0.0275137\n",
            "Loss on test set: 0.0324974\n",
            "Con on train set: 0.0000485\n",
            "Con on test set: 0.0000806\n",
            "\n",
            "8:52:57.735128\n",
            "Reset trainable parameters of layer = Conv3d(1, 16, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=128, bias=True)\n",
            "0:03:20.954118\n",
            "Epoch: 1\n",
            "Loss on train set: 0.0367725\n",
            "Loss on test set: 0.0417492\n",
            "Con on train set: 0.0020520\n",
            "Con on test set: 0.0028080\n",
            "\n",
            "0:08:16.782394\n",
            "0:11:38.299795\n",
            "0:14:59.750338\n",
            "0:18:20.923507\n",
            "0:21:41.969891\n",
            "Epoch: 6\n",
            "Loss on train set: 0.0327685\n",
            "Loss on test set: 0.0395047\n",
            "Con on train set: 0.0005415\n",
            "Con on test set: 0.0008781\n",
            "\n",
            "0:26:36.993286\n",
            "0:29:57.981985\n",
            "0:33:19.181409\n",
            "0:36:40.441307\n",
            "0:40:01.484609\n",
            "Epoch: 11\n",
            "Loss on train set: 0.0333293\n",
            "Loss on test set: 0.0389079\n",
            "Con on train set: 0.0008305\n",
            "Con on test set: 0.0004123\n",
            "\n",
            "0:44:56.815126\n",
            "0:48:17.892783\n",
            "0:51:38.975777\n",
            "0:55:00.012289\n",
            "0:58:20.997232\n",
            "Epoch: 16\n",
            "Loss on train set: 0.0327940\n",
            "Loss on test set: 0.0389893\n",
            "Con on train set: 0.0000916\n",
            "Con on test set: 0.0000924\n",
            "\n",
            "1:03:16.185380\n",
            "1:06:36.884912\n",
            "1:09:57.572600\n",
            "1:13:18.247022\n",
            "1:16:38.942759\n",
            "Epoch: 21\n",
            "Loss on train set: 0.0330298\n",
            "Loss on test set: 0.0388041\n",
            "Con on train set: 0.0000852\n",
            "Con on test set: 0.0000669\n",
            "\n",
            "1:21:33.907411\n",
            "1:24:54.545097\n",
            "1:28:15.257624\n",
            "1:31:36.028535\n",
            "1:34:56.862822\n",
            "Epoch: 26\n",
            "Loss on train set: 0.0331629\n",
            "Loss on test set: 0.0386704\n",
            "Con on train set: 0.0001039\n",
            "Con on test set: 0.0000845\n",
            "\n",
            "1:39:52.144971\n",
            "1:43:12.979513\n",
            "1:46:33.702103\n",
            "1:49:54.335250\n",
            "1:53:14.963335\n",
            "Epoch: 31\n",
            "Loss on train set: 0.0332558\n",
            "Loss on test set: 0.0392702\n",
            "Con on train set: 0.0001222\n",
            "Con on test set: 0.0001224\n",
            "\n",
            "1:58:09.917135\n",
            "2:01:30.773708\n",
            "2:04:51.531666\n",
            "2:08:12.329932\n",
            "2:11:32.961608\n",
            "Epoch: 36\n",
            "Loss on train set: 0.0332106\n",
            "Loss on test set: 0.0395107\n",
            "Con on train set: 0.0000786\n",
            "Con on test set: 0.0000347\n",
            "\n",
            "2:16:27.835950\n",
            "2:19:48.497501\n",
            "2:23:09.156861\n",
            "2:26:29.759810\n",
            "2:29:50.388458\n",
            "Epoch: 41\n",
            "Loss on train set: 0.0332497\n",
            "Loss on test set: 0.0384802\n",
            "Con on train set: 0.0000672\n",
            "Con on test set: 0.0000428\n",
            "\n",
            "2:34:45.525367\n",
            "2:38:06.453006\n",
            "2:41:27.466501\n",
            "2:44:48.347754\n",
            "2:48:09.236216\n",
            "Epoch: 46\n",
            "Loss on train set: 0.0330236\n",
            "Loss on test set: 0.0389331\n",
            "Con on train set: 0.0000705\n",
            "Con on test set: 0.0000298\n",
            "\n",
            "2:53:04.422064\n",
            "2:56:25.342567\n",
            "2:59:46.263356\n",
            "3:03:07.165208\n",
            "3:06:28.077837\n",
            "Epoch: 51\n",
            "Loss on train set: 0.0340038\n",
            "Loss on test set: 0.0380957\n",
            "Con on train set: 0.0001130\n",
            "Con on test set: 0.0000456\n",
            "\n",
            "3:11:23.123714\n",
            "3:14:43.984169\n",
            "3:18:04.900359\n",
            "3:21:25.812505\n",
            "3:24:46.715756\n",
            "Epoch: 56\n",
            "Loss on train set: 0.0327249\n",
            "Loss on test set: 0.0381795\n",
            "Con on train set: 0.0000089\n",
            "Con on test set: 0.0000038\n",
            "\n",
            "3:29:41.896040\n",
            "3:33:02.829387\n",
            "3:36:23.576324\n",
            "3:39:44.242631\n",
            "3:43:05.101444\n",
            "Epoch: 61\n",
            "Loss on train set: 0.0328256\n",
            "Loss on test set: 0.0404118\n",
            "Con on train set: 0.0000083\n",
            "Con on test set: 0.0000095\n",
            "\n",
            "3:48:00.142829\n",
            "3:51:20.865708\n",
            "3:54:41.498559\n",
            "3:58:02.313304\n",
            "4:01:24.056282\n",
            "Epoch: 66\n",
            "Loss on train set: 0.0326299\n",
            "Loss on test set: 0.0385790\n",
            "Con on train set: 0.0000094\n",
            "Con on test set: 0.0000159\n",
            "\n",
            "4:06:20.148863\n",
            "4:09:41.866646\n",
            "4:13:03.625084\n",
            "4:16:25.340711\n",
            "4:19:47.034756\n",
            "Epoch: 71\n",
            "Loss on train set: 0.0323922\n",
            "Loss on test set: 0.0379314\n",
            "Con on train set: 0.0000092\n",
            "Con on test set: 0.0000034\n",
            "\n",
            "4:24:43.124643\n",
            "4:28:04.849420\n",
            "4:31:26.579788\n",
            "4:34:48.339870\n",
            "4:38:10.098593\n",
            "Epoch: 76\n",
            "Loss on train set: 0.0323458\n",
            "Loss on test set: 0.0378945\n",
            "Con on train set: 0.0000123\n",
            "Con on test set: 0.0000288\n",
            "\n",
            "4:43:06.183951\n",
            "4:46:27.925624\n",
            "4:49:49.640684\n",
            "4:53:11.345492\n",
            "4:56:33.258357\n",
            "Epoch: 81\n",
            "Loss on train set: 0.0324562\n",
            "Loss on test set: 0.0383368\n",
            "Con on train set: 0.0000007\n",
            "Con on test set: 0.0000004\n",
            "\n",
            "5:01:28.272294\n",
            "5:04:48.950075\n",
            "5:08:09.678825\n",
            "5:11:30.311260\n",
            "5:14:50.965444\n",
            "Epoch: 86\n",
            "Loss on train set: 0.0323312\n",
            "Loss on test set: 0.0388290\n",
            "Con on train set: 0.0000010\n",
            "Con on test set: 0.0000008\n",
            "\n",
            "5:19:45.845244\n",
            "5:23:06.459189\n",
            "5:26:27.126445\n",
            "5:29:47.776999\n",
            "5:33:08.403684\n",
            "Epoch: 91\n",
            "Loss on train set: 0.0323341\n",
            "Loss on test set: 0.0386241\n",
            "Con on train set: 0.0000007\n",
            "Con on test set: 0.0000006\n",
            "\n",
            "5:38:03.276519\n",
            "5:41:24.000462\n",
            "5:44:44.599683\n",
            "5:48:05.231599\n",
            "5:51:25.867622\n",
            "Epoch: 96\n",
            "Loss on train set: 0.0322911\n",
            "Loss on test set: 0.0381175\n",
            "Con on train set: 0.0000007\n",
            "Con on test set: 0.0000004\n",
            "\n",
            "5:56:21.107408\n",
            "5:59:42.575427\n",
            "6:03:04.188676\n",
            "6:06:25.808581\n",
            "6:09:47.387722\n",
            "Epoch: 101\n",
            "Loss on train set: 0.0324259\n",
            "Loss on test set: 0.0379765\n",
            "Con on train set: 0.0000010\n",
            "Con on test set: 0.0000009\n",
            "\n",
            "6:11:21.779115\n",
            "Reset trainable parameters of layer = Conv3d(1, 16, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "Reset trainable parameters of layer = Linear(in_features=128, out_features=128, bias=True)\n",
            "0:21:25.857398\n",
            "Epoch: 1\n",
            "Loss on train set: 0.0414834\n",
            "Loss on test set: 0.0457679\n",
            "Con on train set: 0.0011095\n",
            "Con on test set: 0.0018453\n",
            "\n",
            "1:03:06.376603\n",
            "1:24:30.501213\n",
            "1:45:58.308906\n",
            "2:07:24.146716\n",
            "2:28:51.802248\n",
            "Epoch: 6\n",
            "Loss on train set: 0.0307724\n",
            "Loss on test set: 0.0342852\n",
            "Con on train set: 0.0007357\n",
            "Con on test set: 0.0005314\n",
            "\n",
            "3:10:39.387668\n",
            "3:32:10.020862\n",
            "3:53:39.678868\n",
            "4:15:06.109274\n",
            "4:36:32.560518\n",
            "Epoch: 11\n",
            "Loss on train set: 0.0305135\n",
            "Loss on test set: 0.0352093\n",
            "Con on train set: 0.0005203\n",
            "Con on test set: 0.0002266\n",
            "\n",
            "5:18:12.874372\n",
            "5:39:39.109523\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5b39131b97de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mnet_res_H2O_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mnet_res_H2O_full_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losss_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losss_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cons_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cons_res_H2O_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_H2Of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader_H2Of\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mnet_res_H2O_full_res_H2O_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_res_H2O_full_res_H2O_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_res_H2O_full_res_H2O_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'drive/MyDrive/Thesis/net_res_H2O_full_res_H2O_full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5cc1556e468a>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(epochs, net, device, train_loader, test_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Set to same device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_loader_H2O = torch.load('test_loader_H2O_3D')\n",
        "train_loader_H2O = torch.load('train_loader_H2O_3D')\n",
        "\n",
        "hidden_channels_res = [16,32,64,128]\n",
        "net_res_H2O = p3DNets.ResNet18_3D_d(in_channels, hidden_channels_res)\n",
        "optimizer_res_H2O = torch.optim.Adam(net_res_H2O.parameters(), lr=learning_rate, weight_decay=0.5)\n",
        "net_res_H2O.apply(reset_weights)\n",
        "net_res_H2O_res_H2O, train_losses_res_H2O, train_losss_res_H2O, test_losss_res_H2O, train_cons_res_H2O, test_cons_res_H2O = train_test(epochs, net_res_H2O, device, train_loader_H2O, test_loader_H2O, optimizer_res_H2O, criterion)\n",
        "net_res_H2O_res_H2O = net_res_H2O_res_H2O.cpu()\n",
        "torch.save(net_res_H2O_res_H2O,'drive/MyDrive/Thesis/net_res_H2O_res_H2O')\n",
        "np.savez('drive/MyDrive/Thesis/net_res_H2O_3D.npz', trainlossd=train_losses_res_H2O, trainlosssd=train_losss_res_H2O, testlosssd=test_losss_res_H2O, traincond=train_cons_res_H2O, testcond=test_cons_res_H2O)\n",
        "\n",
        "test_loader_xyz = torch.load('test_loader_xyz_3D')\n",
        "train_loader_xyz = torch.load('train_loader_xyz_3D')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "3D.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}